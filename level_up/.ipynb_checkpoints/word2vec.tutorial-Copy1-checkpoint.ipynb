{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Next, is our dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data. In this case I am going to use data from the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset. This dataset has full user reviews of cars and hotels. I have specifically concatenated all of the hotel reviews into one big file which is about 97MB compressed and 229MB uncompressed. We will use the compressed file for this tutorial. Each line in this file represents a hotel review. You can download the OpinRank Word2Vec dataset here.\n",
    "\n",
    "To avoid confusion, while gensim’s word2vec tutorial says that you need to pass it a sequence of sentences as its input, you can always pass it a whole review as a sentence (i.e. a much larger size of text), and it should not make much of a difference. \n",
    "\n",
    "Now, let's take a closer look at this data below by printing the first line. You can see that this is a pretty hefty review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into a list\n",
    "Now that we've had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below, that I am directly reading the \n",
    "compressed file. I'm also doing a mild pre-processing of the reviews using `gensim.utils.simple_preprocess (line)`. This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official [Gensim documentation site](https://radimrehurek.com/gensim/utils.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:49:59,805 : INFO : reading file reviews_data.txt.gz...this may take a while\n",
      "2020-08-29 10:49:59,807 : INFO : read 0 reviews\n",
      "2020-08-29 10:50:01,674 : INFO : read 10000 reviews\n",
      "2020-08-29 10:50:03,633 : INFO : read 20000 reviews\n",
      "2020-08-29 10:50:05,863 : INFO : read 30000 reviews\n",
      "2020-08-29 10:50:08,006 : INFO : read 40000 reviews\n",
      "2020-08-29 10:50:10,241 : INFO : read 50000 reviews\n",
      "2020-08-29 10:50:12,424 : INFO : read 60000 reviews\n",
      "2020-08-29 10:50:14,607 : INFO : read 70000 reviews\n",
      "2020-08-29 10:50:16,336 : INFO : read 80000 reviews\n",
      "2020-08-29 10:50:18,222 : INFO : read 90000 reviews\n",
      "2020-08-29 10:50:20,091 : INFO : read 100000 reviews\n",
      "2020-08-29 10:50:21,917 : INFO : read 110000 reviews\n",
      "2020-08-29 10:50:23,742 : INFO : read 120000 reviews\n",
      "2020-08-29 10:50:25,625 : INFO : read 130000 reviews\n",
      "2020-08-29 10:50:27,652 : INFO : read 140000 reviews\n",
      "2020-08-29 10:50:29,514 : INFO : read 150000 reviews\n",
      "2020-08-29 10:50:31,778 : INFO : read 160000 reviews\n",
      "2020-08-29 10:50:33,603 : INFO : read 170000 reviews\n",
      "2020-08-29 10:50:35,571 : INFO : read 180000 reviews\n",
      "2020-08-29 10:50:37,456 : INFO : read 190000 reviews\n",
      "2020-08-29 10:50:39,524 : INFO : read 200000 reviews\n",
      "2020-08-29 10:50:41,501 : INFO : read 210000 reviews\n",
      "2020-08-29 10:50:43,520 : INFO : read 220000 reviews\n",
      "2020-08-29 10:50:45,358 : INFO : read 230000 reviews\n",
      "2020-08-29 10:50:47,180 : INFO : read 240000 reviews\n",
      "2020-08-29 10:50:48,943 : INFO : read 250000 reviews\n",
      "2020-08-29 10:50:50,475 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step (the `documents`). So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.\n",
    "\n",
    "After building the vocabulary, we just need to call `train(...)` to start training the Word2Vec model. Training on the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset takes about 10 minutes so please be patient while running your code on this dataset.\n",
    "\n",
    "Behind the scenes we are actually training a simple neural network with a single hidden layer. But, we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:52:07,432 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2020-08-29 10:52:07,437 : INFO : collecting all words and their counts\n",
      "2020-08-29 10:52:07,438 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-08-29 10:52:07,677 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2020-08-29 10:52:07,890 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2020-08-29 10:52:08,171 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2020-08-29 10:52:08,415 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2020-08-29 10:52:08,672 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2020-08-29 10:52:08,919 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2020-08-29 10:52:09,127 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2020-08-29 10:52:09,318 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2020-08-29 10:52:09,519 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2020-08-29 10:52:09,713 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2020-08-29 10:52:09,917 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2020-08-29 10:52:10,141 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2020-08-29 10:52:10,386 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2020-08-29 10:52:10,623 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2020-08-29 10:52:10,827 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2020-08-29 10:52:11,050 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2020-08-29 10:52:11,285 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2020-08-29 10:52:11,513 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2020-08-29 10:52:11,760 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2020-08-29 10:52:12,055 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2020-08-29 10:52:12,329 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2020-08-29 10:52:12,615 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2020-08-29 10:52:12,860 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2020-08-29 10:52:13,110 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2020-08-29 10:52:13,377 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2020-08-29 10:52:13,507 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2020-08-29 10:52:13,508 : INFO : Loading a fresh vocabulary\n",
      "2020-08-29 10:52:13,678 : INFO : effective_min_count=2 retains 70537 unique words (47% of original 150059, drops 79522)\n",
      "2020-08-29 10:52:13,678 : INFO : effective_min_count=2 leaves 41439836 word corpus (99% of original 41519358, drops 79522)\n",
      "2020-08-29 10:52:13,883 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2020-08-29 10:52:13,886 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2020-08-29 10:52:13,886 : INFO : downsampling leaves estimated 30349251 word corpus (73.2% of prior 41439836)\n",
      "2020-08-29 10:52:14,055 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2020-08-29 10:52:14,056 : INFO : resetting layer weights\n",
      "2020-08-29 10:52:25,130 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-08-29 10:52:26,136 : INFO : EPOCH 1 - PROGRESS: at 5.73% examples, 1766585 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:27,147 : INFO : EPOCH 1 - PROGRESS: at 11.38% examples, 1829410 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:28,148 : INFO : EPOCH 1 - PROGRESS: at 16.85% examples, 1864888 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:29,161 : INFO : EPOCH 1 - PROGRESS: at 22.23% examples, 1876481 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:30,172 : INFO : EPOCH 1 - PROGRESS: at 28.28% examples, 1880303 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:31,178 : INFO : EPOCH 1 - PROGRESS: at 34.89% examples, 1879152 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:32,194 : INFO : EPOCH 1 - PROGRESS: at 41.68% examples, 1874988 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:33,194 : INFO : EPOCH 1 - PROGRESS: at 48.21% examples, 1872043 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:34,199 : INFO : EPOCH 1 - PROGRESS: at 54.07% examples, 1856715 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:35,201 : INFO : EPOCH 1 - PROGRESS: at 59.62% examples, 1829234 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:36,210 : INFO : EPOCH 1 - PROGRESS: at 65.55% examples, 1814659 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:37,210 : INFO : EPOCH 1 - PROGRESS: at 71.00% examples, 1803055 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:38,220 : INFO : EPOCH 1 - PROGRESS: at 76.89% examples, 1798339 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:52:39,224 : INFO : EPOCH 1 - PROGRESS: at 82.63% examples, 1795228 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:40,228 : INFO : EPOCH 1 - PROGRESS: at 88.63% examples, 1792739 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:41,232 : INFO : EPOCH 1 - PROGRESS: at 94.62% examples, 1788934 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:42,094 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:52:42,103 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:52:42,111 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:52:42,115 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:52:42,117 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:52:42,118 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:52:42,121 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:52:42,124 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:52:42,127 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:52:42,133 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:52:42,134 : INFO : EPOCH - 1 : training on 41519358 raw words (30349061 effective words) took 17.0s, 1785474 effective words/s\n",
      "2020-08-29 10:52:43,140 : INFO : EPOCH 2 - PROGRESS: at 5.45% examples, 1679273 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:44,146 : INFO : EPOCH 2 - PROGRESS: at 10.57% examples, 1682095 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:45,156 : INFO : EPOCH 2 - PROGRESS: at 14.70% examples, 1610127 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:46,159 : INFO : EPOCH 2 - PROGRESS: at 18.96% examples, 1591826 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:47,162 : INFO : EPOCH 2 - PROGRESS: at 23.10% examples, 1572230 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:48,177 : INFO : EPOCH 2 - PROGRESS: at 27.94% examples, 1551382 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:49,198 : INFO : EPOCH 2 - PROGRESS: at 33.42% examples, 1544601 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:50,199 : INFO : EPOCH 2 - PROGRESS: at 38.89% examples, 1547776 words/s, in_qsize 20, out_qsize 1\n",
      "2020-08-29 10:52:51,204 : INFO : EPOCH 2 - PROGRESS: at 44.65% examples, 1550375 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:52,208 : INFO : EPOCH 2 - PROGRESS: at 49.81% examples, 1543083 words/s, in_qsize 17, out_qsize 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:52:53,217 : INFO : EPOCH 2 - PROGRESS: at 54.46% examples, 1529330 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:52:54,220 : INFO : EPOCH 2 - PROGRESS: at 59.35% examples, 1517830 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:55,222 : INFO : EPOCH 2 - PROGRESS: at 64.67% examples, 1514442 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:56,231 : INFO : EPOCH 2 - PROGRESS: at 69.66% examples, 1513998 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:52:57,233 : INFO : EPOCH 2 - PROGRESS: at 74.84% examples, 1514722 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:52:58,245 : INFO : EPOCH 2 - PROGRESS: at 79.33% examples, 1507655 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:52:59,258 : INFO : EPOCH 2 - PROGRESS: at 84.00% examples, 1501698 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:00,267 : INFO : EPOCH 2 - PROGRESS: at 89.33% examples, 1503547 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:01,275 : INFO : EPOCH 2 - PROGRESS: at 94.79% examples, 1507339 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:02,245 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:53:02,270 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:53:02,272 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:53:02,274 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:53:02,275 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:53:02,276 : INFO : EPOCH 2 - PROGRESS: at 99.91% examples, 1505798 words/s, in_qsize 4, out_qsize 1\n",
      "2020-08-29 10:53:02,277 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:53:02,286 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:53:02,288 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:53:02,291 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:53:02,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:53:02,293 : INFO : EPOCH - 2 : training on 41519358 raw words (30347998 effective words) took 20.2s, 1505789 effective words/s\n",
      "2020-08-29 10:53:03,305 : INFO : EPOCH 3 - PROGRESS: at 4.43% examples, 1354133 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:04,321 : INFO : EPOCH 3 - PROGRESS: at 8.95% examples, 1378432 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:05,325 : INFO : EPOCH 3 - PROGRESS: at 13.03% examples, 1420202 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:06,336 : INFO : EPOCH 3 - PROGRESS: at 17.59% examples, 1460994 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:07,344 : INFO : EPOCH 3 - PROGRESS: at 22.01% examples, 1481335 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:53:08,350 : INFO : EPOCH 3 - PROGRESS: at 26.58% examples, 1488563 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:09,352 : INFO : EPOCH 3 - PROGRESS: at 32.00% examples, 1487902 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:10,354 : INFO : EPOCH 3 - PROGRESS: at 37.10% examples, 1487492 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:11,365 : INFO : EPOCH 3 - PROGRESS: at 42.24% examples, 1477297 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:12,388 : INFO : EPOCH 3 - PROGRESS: at 47.16% examples, 1465563 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:13,392 : INFO : EPOCH 3 - PROGRESS: at 52.56% examples, 1474420 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:14,398 : INFO : EPOCH 3 - PROGRESS: at 58.01% examples, 1483795 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:15,399 : INFO : EPOCH 3 - PROGRESS: at 63.56% examples, 1491407 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:16,401 : INFO : EPOCH 3 - PROGRESS: at 69.03% examples, 1499046 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:17,404 : INFO : EPOCH 3 - PROGRESS: at 74.38% examples, 1504880 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:18,426 : INFO : EPOCH 3 - PROGRESS: at 78.90% examples, 1498740 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:53:19,427 : INFO : EPOCH 3 - PROGRESS: at 83.65% examples, 1494928 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:20,437 : INFO : EPOCH 3 - PROGRESS: at 88.91% examples, 1496288 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:21,443 : INFO : EPOCH 3 - PROGRESS: at 93.82% examples, 1492256 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:22,456 : INFO : EPOCH 3 - PROGRESS: at 99.17% examples, 1494278 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:22,560 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:53:22,577 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:53:22,581 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:53:22,584 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:53:22,586 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:53:22,588 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:53:22,594 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:53:22,601 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:53:22,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:53:22,606 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:53:22,607 : INFO : EPOCH - 3 : training on 41519358 raw words (30354742 effective words) took 20.3s, 1494640 effective words/s\n",
      "2020-08-29 10:53:23,613 : INFO : EPOCH 4 - PROGRESS: at 4.43% examples, 1364501 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:24,618 : INFO : EPOCH 4 - PROGRESS: at 9.03% examples, 1405542 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:25,621 : INFO : EPOCH 4 - PROGRESS: at 12.96% examples, 1421620 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:26,634 : INFO : EPOCH 4 - PROGRESS: at 17.38% examples, 1447487 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:27,654 : INFO : EPOCH 4 - PROGRESS: at 21.52% examples, 1445627 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:28,655 : INFO : EPOCH 4 - PROGRESS: at 25.65% examples, 1450226 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:29,667 : INFO : EPOCH 4 - PROGRESS: at 30.61% examples, 1436675 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:30,667 : INFO : EPOCH 4 - PROGRESS: at 35.88% examples, 1444660 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:31,681 : INFO : EPOCH 4 - PROGRESS: at 41.53% examples, 1455532 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:32,696 : INFO : EPOCH 4 - PROGRESS: at 47.20% examples, 1467698 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:53:33,698 : INFO : EPOCH 4 - PROGRESS: at 52.68% examples, 1479023 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:34,706 : INFO : EPOCH 4 - PROGRESS: at 58.17% examples, 1488418 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:35,709 : INFO : EPOCH 4 - PROGRESS: at 62.99% examples, 1481110 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:36,723 : INFO : EPOCH 4 - PROGRESS: at 68.09% examples, 1478108 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:37,725 : INFO : EPOCH 4 - PROGRESS: at 73.06% examples, 1479266 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:38,734 : INFO : EPOCH 4 - PROGRESS: at 77.90% examples, 1479586 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:39,734 : INFO : EPOCH 4 - PROGRESS: at 82.90% examples, 1481927 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:40,752 : INFO : EPOCH 4 - PROGRESS: at 87.79% examples, 1478527 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:41,754 : INFO : EPOCH 4 - PROGRESS: at 92.93% examples, 1478774 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:42,764 : INFO : EPOCH 4 - PROGRESS: at 97.20% examples, 1466296 words/s, in_qsize 18, out_qsize 2\n",
      "2020-08-29 10:53:43,389 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:53:43,397 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:53:43,398 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:53:43,399 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:53:43,401 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:53:43,402 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:53:43,415 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:53:43,423 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:53:43,424 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:53:43,425 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:53:43,426 : INFO : EPOCH - 4 : training on 41519358 raw words (30351630 effective words) took 20.8s, 1458296 effective words/s\n",
      "2020-08-29 10:53:44,450 : INFO : EPOCH 5 - PROGRESS: at 3.34% examples, 1023312 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:45,471 : INFO : EPOCH 5 - PROGRESS: at 6.48% examples, 980712 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:46,478 : INFO : EPOCH 5 - PROGRESS: at 9.28% examples, 951875 words/s, in_qsize 20, out_qsize 1\n",
      "2020-08-29 10:53:47,481 : INFO : EPOCH 5 - PROGRESS: at 11.24% examples, 898652 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:48,491 : INFO : EPOCH 5 - PROGRESS: at 13.42% examples, 872832 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:49,526 : INFO : EPOCH 5 - PROGRESS: at 15.04% examples, 819122 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:50,565 : INFO : EPOCH 5 - PROGRESS: at 16.92% examples, 790840 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:53:51,572 : INFO : EPOCH 5 - PROGRESS: at 18.50% examples, 764676 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:52,588 : INFO : EPOCH 5 - PROGRESS: at 19.85% examples, 737611 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:53,591 : INFO : EPOCH 5 - PROGRESS: at 21.04% examples, 712102 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:54,640 : INFO : EPOCH 5 - PROGRESS: at 22.44% examples, 681164 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:53:55,670 : INFO : EPOCH 5 - PROGRESS: at 23.29% examples, 651446 words/s, in_qsize 17, out_qsize 7\n",
      "2020-08-29 10:53:56,678 : INFO : EPOCH 5 - PROGRESS: at 24.32% examples, 632269 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:57,709 : INFO : EPOCH 5 - PROGRESS: at 25.63% examples, 613267 words/s, in_qsize 20, out_qsize 0\n",
      "2020-08-29 10:53:58,727 : INFO : EPOCH 5 - PROGRESS: at 26.81% examples, 593726 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:53:59,743 : INFO : EPOCH 5 - PROGRESS: at 28.17% examples, 578443 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:00,752 : INFO : EPOCH 5 - PROGRESS: at 29.83% examples, 571769 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:01,770 : INFO : EPOCH 5 - PROGRESS: at 31.88% examples, 569967 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:02,802 : INFO : EPOCH 5 - PROGRESS: at 33.44% examples, 563383 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:03,817 : INFO : EPOCH 5 - PROGRESS: at 35.23% examples, 561584 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:04,832 : INFO : EPOCH 5 - PROGRESS: at 37.57% examples, 566277 words/s, in_qsize 20, out_qsize 0\n",
      "2020-08-29 10:54:05,838 : INFO : EPOCH 5 - PROGRESS: at 40.29% examples, 574617 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:06,858 : INFO : EPOCH 5 - PROGRESS: at 43.18% examples, 583397 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:07,869 : INFO : EPOCH 5 - PROGRESS: at 46.42% examples, 595874 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:08,870 : INFO : EPOCH 5 - PROGRESS: at 49.78% examples, 610640 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:09,874 : INFO : EPOCH 5 - PROGRESS: at 53.41% examples, 629042 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:10,882 : INFO : EPOCH 5 - PROGRESS: at 57.72% examples, 650747 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:11,884 : INFO : EPOCH 5 - PROGRESS: at 62.11% examples, 672836 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:54:12,894 : INFO : EPOCH 5 - PROGRESS: at 67.21% examples, 699052 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:13,894 : INFO : EPOCH 5 - PROGRESS: at 72.20% examples, 726039 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:14,899 : INFO : EPOCH 5 - PROGRESS: at 77.33% examples, 752254 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:15,902 : INFO : EPOCH 5 - PROGRESS: at 82.59% examples, 778467 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:16,905 : INFO : EPOCH 5 - PROGRESS: at 88.24% examples, 805235 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:17,917 : INFO : EPOCH 5 - PROGRESS: at 94.23% examples, 831677 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:18,851 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:54:18,864 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:54:18,870 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:54:18,871 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:54:18,872 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:54:18,873 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:54:18,881 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:54:18,887 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:54:18,888 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:54:18,889 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:54:18,889 : INFO : EPOCH - 5 : training on 41519358 raw words (30347629 effective words) took 35.5s, 855948 effective words/s\n",
      "2020-08-29 10:54:18,890 : INFO : training on a 207596790 raw words (151751060 effective words) took 113.8s, 1333977 effective words/s\n",
      "2020-08-29 10:54:18,890 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-08-29 10:54:18,891 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-08-29 10:54:19,900 : INFO : EPOCH 1 - PROGRESS: at 5.52% examples, 1698347 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:20,913 : INFO : EPOCH 1 - PROGRESS: at 10.65% examples, 1691183 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:21,915 : INFO : EPOCH 1 - PROGRESS: at 15.47% examples, 1696899 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:22,918 : INFO : EPOCH 1 - PROGRESS: at 20.03% examples, 1697449 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:23,919 : INFO : EPOCH 1 - PROGRESS: at 24.64% examples, 1692061 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:24,921 : INFO : EPOCH 1 - PROGRESS: at 30.80% examples, 1689832 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:25,927 : INFO : EPOCH 1 - PROGRESS: at 36.72% examples, 1688344 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:26,927 : INFO : EPOCH 1 - PROGRESS: at 42.43% examples, 1676256 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:27,931 : INFO : EPOCH 1 - PROGRESS: at 48.07% examples, 1666314 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:28,932 : INFO : EPOCH 1 - PROGRESS: at 53.34% examples, 1655568 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:29,939 : INFO : EPOCH 1 - PROGRESS: at 58.65% examples, 1642738 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:30,940 : INFO : EPOCH 1 - PROGRESS: at 63.90% examples, 1629354 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:31,958 : INFO : EPOCH 1 - PROGRESS: at 68.98% examples, 1616806 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:32,963 : INFO : EPOCH 1 - PROGRESS: at 73.69% examples, 1601202 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:33,980 : INFO : EPOCH 1 - PROGRESS: at 77.65% examples, 1576689 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:54:34,981 : INFO : EPOCH 1 - PROGRESS: at 81.76% examples, 1556903 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:35,981 : INFO : EPOCH 1 - PROGRESS: at 86.00% examples, 1541481 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:54:36,995 : INFO : EPOCH 1 - PROGRESS: at 90.78% examples, 1528928 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:54:38,008 : INFO : EPOCH 1 - PROGRESS: at 95.16% examples, 1515133 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:39,013 : INFO : EPOCH 1 - PROGRESS: at 99.54% examples, 1502473 words/s, in_qsize 18, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:54:39,065 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:54:39,070 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:54:39,075 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:54:39,078 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:54:39,080 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:54:39,085 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:54:39,092 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:54:39,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:54:39,099 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:54:39,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:54:39,102 : INFO : EPOCH - 1 : training on 41519358 raw words (30348245 effective words) took 20.2s, 1502137 effective words/s\n",
      "2020-08-29 10:54:40,116 : INFO : EPOCH 2 - PROGRESS: at 3.91% examples, 1202651 words/s, in_qsize 20, out_qsize 2\n",
      "2020-08-29 10:54:41,117 : INFO : EPOCH 2 - PROGRESS: at 7.95% examples, 1227435 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:54:42,122 : INFO : EPOCH 2 - PROGRESS: at 11.45% examples, 1233033 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:54:43,133 : INFO : EPOCH 2 - PROGRESS: at 14.96% examples, 1232595 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:44,135 : INFO : EPOCH 2 - PROGRESS: at 18.77% examples, 1257608 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:45,137 : INFO : EPOCH 2 - PROGRESS: at 22.49% examples, 1269585 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:46,138 : INFO : EPOCH 2 - PROGRESS: at 26.39% examples, 1274397 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:47,142 : INFO : EPOCH 2 - PROGRESS: at 31.03% examples, 1275010 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:48,144 : INFO : EPOCH 2 - PROGRESS: at 35.25% examples, 1267702 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:49,148 : INFO : EPOCH 2 - PROGRESS: at 40.06% examples, 1275890 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:54:50,149 : INFO : EPOCH 2 - PROGRESS: at 44.73% examples, 1275162 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:51,164 : INFO : EPOCH 2 - PROGRESS: at 49.61% examples, 1284320 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:52,173 : INFO : EPOCH 2 - PROGRESS: at 54.10% examples, 1288643 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:53,177 : INFO : EPOCH 2 - PROGRESS: at 58.71% examples, 1290265 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:54,188 : INFO : EPOCH 2 - PROGRESS: at 63.15% examples, 1288734 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:55,209 : INFO : EPOCH 2 - PROGRESS: at 67.98% examples, 1293098 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:56,221 : INFO : EPOCH 2 - PROGRESS: at 72.46% examples, 1296718 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:54:57,223 : INFO : EPOCH 2 - PROGRESS: at 76.70% examples, 1295722 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:54:58,233 : INFO : EPOCH 2 - PROGRESS: at 81.31% examples, 1302141 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:54:59,255 : INFO : EPOCH 2 - PROGRESS: at 85.96% examples, 1306390 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:00,268 : INFO : EPOCH 2 - PROGRESS: at 90.85% examples, 1308743 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:01,283 : INFO : EPOCH 2 - PROGRESS: at 95.01% examples, 1303815 words/s, in_qsize 20, out_qsize 0\n",
      "2020-08-29 10:55:02,290 : INFO : EPOCH 2 - PROGRESS: at 99.62% examples, 1304675 words/s, in_qsize 14, out_qsize 1\n",
      "2020-08-29 10:55:02,308 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:55:02,322 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:55:02,326 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:55:02,329 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:55:02,332 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:55:02,333 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:55:02,342 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:55:02,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:55:02,351 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:55:02,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:55:02,353 : INFO : EPOCH - 2 : training on 41519358 raw words (30350109 effective words) took 23.2s, 1305671 effective words/s\n",
      "2020-08-29 10:55:03,381 : INFO : EPOCH 3 - PROGRESS: at 4.43% examples, 1336074 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:04,385 : INFO : EPOCH 3 - PROGRESS: at 9.33% examples, 1437575 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:05,402 : INFO : EPOCH 3 - PROGRESS: at 13.38% examples, 1446324 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:55:06,411 : INFO : EPOCH 3 - PROGRESS: at 17.63% examples, 1459818 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:07,413 : INFO : EPOCH 3 - PROGRESS: at 21.79% examples, 1462366 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:08,416 : INFO : EPOCH 3 - PROGRESS: at 25.82% examples, 1455583 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:09,416 : INFO : EPOCH 3 - PROGRESS: at 30.70% examples, 1439536 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:10,428 : INFO : EPOCH 3 - PROGRESS: at 35.04% examples, 1412832 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:11,435 : INFO : EPOCH 3 - PROGRESS: at 39.60% examples, 1398265 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:12,436 : INFO : EPOCH 3 - PROGRESS: at 44.01% examples, 1378902 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:13,442 : INFO : EPOCH 3 - PROGRESS: at 48.26% examples, 1362967 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:14,451 : INFO : EPOCH 3 - PROGRESS: at 52.49% examples, 1350869 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:15,452 : INFO : EPOCH 3 - PROGRESS: at 56.76% examples, 1343679 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:16,460 : INFO : EPOCH 3 - PROGRESS: at 61.26% examples, 1339933 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:17,464 : INFO : EPOCH 3 - PROGRESS: at 65.87% examples, 1337743 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:18,468 : INFO : EPOCH 3 - PROGRESS: at 70.02% examples, 1332378 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:19,486 : INFO : EPOCH 3 - PROGRESS: at 74.45% examples, 1328534 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:20,490 : INFO : EPOCH 3 - PROGRESS: at 78.43% examples, 1324875 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:21,501 : INFO : EPOCH 3 - PROGRESS: at 82.61% examples, 1321119 words/s, in_qsize 17, out_qsize 3\n",
      "2020-08-29 10:55:22,503 : INFO : EPOCH 3 - PROGRESS: at 87.03% examples, 1321426 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:23,512 : INFO : EPOCH 3 - PROGRESS: at 91.41% examples, 1316837 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:24,515 : INFO : EPOCH 3 - PROGRESS: at 95.66% examples, 1313313 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:25,452 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:55:25,478 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:55:25,480 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:55:25,482 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:55:25,482 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:55:25,483 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:55:25,495 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:55:25,500 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:55:25,501 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:55:25,503 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:55:25,504 : INFO : EPOCH - 3 : training on 41519358 raw words (30352803 effective words) took 23.1s, 1311514 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:55:26,518 : INFO : EPOCH 4 - PROGRESS: at 4.34% examples, 1324205 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:27,529 : INFO : EPOCH 4 - PROGRESS: at 8.76% examples, 1341408 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:28,544 : INFO : EPOCH 4 - PROGRESS: at 12.56% examples, 1368847 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:29,558 : INFO : EPOCH 4 - PROGRESS: at 17.01% examples, 1401681 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:30,559 : INFO : EPOCH 4 - PROGRESS: at 20.92% examples, 1422598 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:31,570 : INFO : EPOCH 4 - PROGRESS: at 25.39% examples, 1434020 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:32,572 : INFO : EPOCH 4 - PROGRESS: at 30.92% examples, 1446273 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:33,573 : INFO : EPOCH 4 - PROGRESS: at 36.33% examples, 1457294 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:34,583 : INFO : EPOCH 4 - PROGRESS: at 41.95% examples, 1466609 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:35,586 : INFO : EPOCH 4 - PROGRESS: at 47.34% examples, 1472877 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:36,598 : INFO : EPOCH 4 - PROGRESS: at 52.65% examples, 1478021 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:37,613 : INFO : EPOCH 4 - PROGRESS: at 57.99% examples, 1482974 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:38,614 : INFO : EPOCH 4 - PROGRESS: at 63.35% examples, 1486847 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:39,630 : INFO : EPOCH 4 - PROGRESS: at 68.51% examples, 1486168 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:40,646 : INFO : EPOCH 4 - PROGRESS: at 73.70% examples, 1487750 words/s, in_qsize 20, out_qsize 2\n",
      "2020-08-29 10:55:41,651 : INFO : EPOCH 4 - PROGRESS: at 78.41% examples, 1487489 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:42,651 : INFO : EPOCH 4 - PROGRESS: at 83.10% examples, 1483466 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:43,652 : INFO : EPOCH 4 - PROGRESS: at 88.35% examples, 1487325 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:44,674 : INFO : EPOCH 4 - PROGRESS: at 93.67% examples, 1488232 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:45,689 : INFO : EPOCH 4 - PROGRESS: at 98.99% examples, 1489462 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:45,839 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:55:45,851 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:55:45,857 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:55:45,859 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:55:45,860 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:55:45,861 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:55:45,863 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:55:45,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:55:45,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:55:45,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:55:45,876 : INFO : EPOCH - 4 : training on 41519358 raw words (30348594 effective words) took 20.4s, 1490139 effective words/s\n",
      "2020-08-29 10:55:46,901 : INFO : EPOCH 5 - PROGRESS: at 4.38% examples, 1323761 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:47,907 : INFO : EPOCH 5 - PROGRESS: at 8.99% examples, 1384547 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:48,914 : INFO : EPOCH 5 - PROGRESS: at 12.86% examples, 1400902 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:49,920 : INFO : EPOCH 5 - PROGRESS: at 16.84% examples, 1389044 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:50,926 : INFO : EPOCH 5 - PROGRESS: at 20.41% examples, 1381081 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:51,928 : INFO : EPOCH 5 - PROGRESS: at 24.18% examples, 1376559 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:52,929 : INFO : EPOCH 5 - PROGRESS: at 28.59% examples, 1356334 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:55:53,936 : INFO : EPOCH 5 - PROGRESS: at 33.31% examples, 1349544 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:54,938 : INFO : EPOCH 5 - PROGRESS: at 37.90% examples, 1347730 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:55:55,938 : INFO : EPOCH 5 - PROGRESS: at 42.65% examples, 1344860 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:56,944 : INFO : EPOCH 5 - PROGRESS: at 47.20% examples, 1337871 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:57,955 : INFO : EPOCH 5 - PROGRESS: at 51.83% examples, 1336168 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:55:58,962 : INFO : EPOCH 5 - PROGRESS: at 56.28% examples, 1333728 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:55:59,965 : INFO : EPOCH 5 - PROGRESS: at 60.86% examples, 1332804 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:00,965 : INFO : EPOCH 5 - PROGRESS: at 65.59% examples, 1333405 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:01,968 : INFO : EPOCH 5 - PROGRESS: at 70.11% examples, 1335971 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:02,970 : INFO : EPOCH 5 - PROGRESS: at 74.98% examples, 1341153 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:03,979 : INFO : EPOCH 5 - PROGRESS: at 79.25% examples, 1340819 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:04,984 : INFO : EPOCH 5 - PROGRESS: at 83.28% examples, 1334316 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:06,000 : INFO : EPOCH 5 - PROGRESS: at 87.47% examples, 1329163 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:07,013 : INFO : EPOCH 5 - PROGRESS: at 92.21% examples, 1328721 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:08,014 : INFO : EPOCH 5 - PROGRESS: at 96.51% examples, 1326038 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:08,765 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:56:08,767 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:56:08,775 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:56:08,777 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:56:08,779 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:56:08,785 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:56:08,789 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:56:08,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:56:08,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:56:08,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:56:08,799 : INFO : EPOCH - 5 : training on 41519358 raw words (30352889 effective words) took 22.9s, 1324469 effective words/s\n",
      "2020-08-29 10:56:09,809 : INFO : EPOCH 6 - PROGRESS: at 4.34% examples, 1328757 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:10,815 : INFO : EPOCH 6 - PROGRESS: at 8.57% examples, 1318936 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:11,816 : INFO : EPOCH 6 - PROGRESS: at 12.07% examples, 1314636 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:12,818 : INFO : EPOCH 6 - PROGRESS: at 15.82% examples, 1306413 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:13,818 : INFO : EPOCH 6 - PROGRESS: at 19.32% examples, 1306518 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:14,820 : INFO : EPOCH 6 - PROGRESS: at 22.99% examples, 1304625 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:15,821 : INFO : EPOCH 6 - PROGRESS: at 27.32% examples, 1312756 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:16,831 : INFO : EPOCH 6 - PROGRESS: at 31.94% examples, 1304743 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:17,832 : INFO : EPOCH 6 - PROGRESS: at 36.37% examples, 1302402 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:18,834 : INFO : EPOCH 6 - PROGRESS: at 41.34% examples, 1311778 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:19,848 : INFO : EPOCH 6 - PROGRESS: at 45.99% examples, 1306921 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:20,858 : INFO : EPOCH 6 - PROGRESS: at 50.53% examples, 1306105 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:56:21,865 : INFO : EPOCH 6 - PROGRESS: at 55.23% examples, 1312960 words/s, in_qsize 20, out_qsize 0\n",
      "2020-08-29 10:56:22,871 : INFO : EPOCH 6 - PROGRESS: at 60.15% examples, 1320304 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:23,879 : INFO : EPOCH 6 - PROGRESS: at 65.03% examples, 1321595 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:24,883 : INFO : EPOCH 6 - PROGRESS: at 69.47% examples, 1323490 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:25,883 : INFO : EPOCH 6 - PROGRESS: at 74.17% examples, 1327041 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:26,895 : INFO : EPOCH 6 - PROGRESS: at 78.47% examples, 1328446 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:27,897 : INFO : EPOCH 6 - PROGRESS: at 82.68% examples, 1325502 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:28,908 : INFO : EPOCH 6 - PROGRESS: at 87.16% examples, 1325740 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:29,922 : INFO : EPOCH 6 - PROGRESS: at 91.91% examples, 1325697 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:30,938 : INFO : EPOCH 6 - PROGRESS: at 96.51% examples, 1325878 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:31,623 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:56:31,627 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:56:31,631 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:56:31,633 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:56:31,634 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:56:31,640 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:56:31,645 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:56:31,651 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:56:31,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:56:31,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:56:31,655 : INFO : EPOCH - 6 : training on 41519358 raw words (30351329 effective words) took 22.9s, 1328202 effective words/s\n",
      "2020-08-29 10:56:32,666 : INFO : EPOCH 7 - PROGRESS: at 4.01% examples, 1237185 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:33,679 : INFO : EPOCH 7 - PROGRESS: at 8.09% examples, 1243835 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:34,684 : INFO : EPOCH 7 - PROGRESS: at 11.74% examples, 1272538 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:35,700 : INFO : EPOCH 7 - PROGRESS: at 15.51% examples, 1271491 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:56:36,705 : INFO : EPOCH 7 - PROGRESS: at 19.11% examples, 1282114 words/s, in_qsize 20, out_qsize 3\n",
      "2020-08-29 10:56:37,705 : INFO : EPOCH 7 - PROGRESS: at 22.75% examples, 1282073 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:38,707 : INFO : EPOCH 7 - PROGRESS: at 27.02% examples, 1296144 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:39,707 : INFO : EPOCH 7 - PROGRESS: at 31.74% examples, 1294518 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:40,726 : INFO : EPOCH 7 - PROGRESS: at 36.50% examples, 1301937 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:41,731 : INFO : EPOCH 7 - PROGRESS: at 41.10% examples, 1300041 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:42,742 : INFO : EPOCH 7 - PROGRESS: at 45.69% examples, 1294622 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:43,743 : INFO : EPOCH 7 - PROGRESS: at 50.31% examples, 1298233 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:44,750 : INFO : EPOCH 7 - PROGRESS: at 54.86% examples, 1303977 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:56:45,752 : INFO : EPOCH 7 - PROGRESS: at 59.84% examples, 1311319 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:46,755 : INFO : EPOCH 7 - PROGRESS: at 64.71% examples, 1313763 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:47,769 : INFO : EPOCH 7 - PROGRESS: at 69.43% examples, 1320162 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:48,769 : INFO : EPOCH 7 - PROGRESS: at 74.24% examples, 1326011 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:49,771 : INFO : EPOCH 7 - PROGRESS: at 78.63% examples, 1329328 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:50,772 : INFO : EPOCH 7 - PROGRESS: at 83.09% examples, 1330526 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:51,779 : INFO : EPOCH 7 - PROGRESS: at 87.83% examples, 1333747 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:56:52,780 : INFO : EPOCH 7 - PROGRESS: at 92.58% examples, 1335127 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:53,781 : INFO : EPOCH 7 - PROGRESS: at 97.32% examples, 1336983 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:54,265 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:56:54,268 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:56:54,287 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:56:54,289 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:56:54,290 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:56:54,293 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:56:54,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:56:54,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:56:54,306 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:56:54,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:56:54,309 : INFO : EPOCH - 7 : training on 41519358 raw words (30348700 effective words) took 22.6s, 1340063 effective words/s\n",
      "2020-08-29 10:56:55,316 : INFO : EPOCH 8 - PROGRESS: at 4.54% examples, 1403951 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:56:56,319 : INFO : EPOCH 8 - PROGRESS: at 8.99% examples, 1396768 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:57,320 : INFO : EPOCH 8 - PROGRESS: at 12.81% examples, 1407362 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:58,329 : INFO : EPOCH 8 - PROGRESS: at 17.11% examples, 1423619 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:56:59,343 : INFO : EPOCH 8 - PROGRESS: at 21.03% examples, 1436241 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:00,346 : INFO : EPOCH 8 - PROGRESS: at 25.49% examples, 1444747 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:01,350 : INFO : EPOCH 8 - PROGRESS: at 30.85% examples, 1448201 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:02,358 : INFO : EPOCH 8 - PROGRESS: at 35.99% examples, 1449776 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:03,372 : INFO : EPOCH 8 - PROGRESS: at 40.93% examples, 1440918 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:04,374 : INFO : EPOCH 8 - PROGRESS: at 46.20% examples, 1440008 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:05,381 : INFO : EPOCH 8 - PROGRESS: at 51.09% examples, 1437890 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:06,396 : INFO : EPOCH 8 - PROGRESS: at 55.94% examples, 1435219 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:07,397 : INFO : EPOCH 8 - PROGRESS: at 61.05% examples, 1438721 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:08,400 : INFO : EPOCH 8 - PROGRESS: at 65.65% examples, 1428933 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:09,408 : INFO : EPOCH 8 - PROGRESS: at 70.13% examples, 1423862 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:10,427 : INFO : EPOCH 8 - PROGRESS: at 74.98% examples, 1421920 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:57:11,428 : INFO : EPOCH 8 - PROGRESS: at 79.47% examples, 1421691 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:12,437 : INFO : EPOCH 8 - PROGRESS: at 83.73% examples, 1413989 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:13,440 : INFO : EPOCH 8 - PROGRESS: at 87.66% examples, 1400428 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:14,441 : INFO : EPOCH 8 - PROGRESS: at 92.29% examples, 1395747 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:15,453 : INFO : EPOCH 8 - PROGRESS: at 96.51% examples, 1388026 words/s, in_qsize 17, out_qsize 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:57:16,180 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:57:16,183 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:57:16,201 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:57:16,206 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:57:16,207 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:57:16,212 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:57:16,221 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:57:16,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:57:16,233 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:57:16,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:57:16,236 : INFO : EPOCH - 8 : training on 41519358 raw words (30345578 effective words) took 21.9s, 1384277 effective words/s\n",
      "2020-08-29 10:57:17,243 : INFO : EPOCH 9 - PROGRESS: at 4.06% examples, 1254233 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:18,244 : INFO : EPOCH 9 - PROGRESS: at 8.03% examples, 1245403 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:19,244 : INFO : EPOCH 9 - PROGRESS: at 11.65% examples, 1266575 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:20,247 : INFO : EPOCH 9 - PROGRESS: at 15.30% examples, 1265741 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:21,257 : INFO : EPOCH 9 - PROGRESS: at 18.90% examples, 1270377 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:22,267 : INFO : EPOCH 9 - PROGRESS: at 22.52% examples, 1272528 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:23,268 : INFO : EPOCH 9 - PROGRESS: at 26.44% examples, 1276722 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:57:24,280 : INFO : EPOCH 9 - PROGRESS: at 31.32% examples, 1282312 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:25,280 : INFO : EPOCH 9 - PROGRESS: at 35.82% examples, 1285637 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:26,281 : INFO : EPOCH 9 - PROGRESS: at 40.78% examples, 1296692 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:27,291 : INFO : EPOCH 9 - PROGRESS: at 45.95% examples, 1304698 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:28,294 : INFO : EPOCH 9 - PROGRESS: at 50.95% examples, 1316210 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:29,313 : INFO : EPOCH 9 - PROGRESS: at 55.94% examples, 1326736 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:30,316 : INFO : EPOCH 9 - PROGRESS: at 60.90% examples, 1334408 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:31,332 : INFO : EPOCH 9 - PROGRESS: at 66.04% examples, 1342092 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:57:32,333 : INFO : EPOCH 9 - PROGRESS: at 70.76% examples, 1347532 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:57:33,337 : INFO : EPOCH 9 - PROGRESS: at 75.13% examples, 1343393 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:34,344 : INFO : EPOCH 9 - PROGRESS: at 78.69% examples, 1331112 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:35,359 : INFO : EPOCH 9 - PROGRESS: at 82.91% examples, 1327180 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:57:36,374 : INFO : EPOCH 9 - PROGRESS: at 87.23% examples, 1324905 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:57:37,387 : INFO : EPOCH 9 - PROGRESS: at 92.44% examples, 1331172 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:38,388 : INFO : EPOCH 9 - PROGRESS: at 97.29% examples, 1335079 words/s, in_qsize 20, out_qsize 1\n",
      "2020-08-29 10:57:39,053 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:57:39,082 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:57:39,085 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:57:39,087 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:57:39,088 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:57:39,089 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:57:39,099 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-29 10:57:39,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:57:39,108 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:57:39,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:57:39,113 : INFO : EPOCH - 9 : training on 41519358 raw words (30350163 effective words) took 22.9s, 1326962 effective words/s\n",
      "2020-08-29 10:57:40,124 : INFO : EPOCH 10 - PROGRESS: at 4.39% examples, 1341203 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:41,129 : INFO : EPOCH 10 - PROGRESS: at 8.93% examples, 1383243 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:42,141 : INFO : EPOCH 10 - PROGRESS: at 12.60% examples, 1378972 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:43,158 : INFO : EPOCH 10 - PROGRESS: at 16.51% examples, 1360320 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:57:44,163 : INFO : EPOCH 10 - PROGRESS: at 19.84% examples, 1338268 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:45,169 : INFO : EPOCH 10 - PROGRESS: at 23.14% examples, 1307850 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:46,170 : INFO : EPOCH 10 - PROGRESS: at 26.86% examples, 1289799 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:57:47,192 : INFO : EPOCH 10 - PROGRESS: at 31.24% examples, 1274939 words/s, in_qsize 16, out_qsize 3\n",
      "2020-08-29 10:57:48,196 : INFO : EPOCH 10 - PROGRESS: at 34.50% examples, 1237144 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:49,226 : INFO : EPOCH 10 - PROGRESS: at 38.03% examples, 1211578 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:57:50,227 : INFO : EPOCH 10 - PROGRESS: at 41.56% examples, 1188801 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:51,247 : INFO : EPOCH 10 - PROGRESS: at 45.56% examples, 1179034 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:52,253 : INFO : EPOCH 10 - PROGRESS: at 49.47% examples, 1174841 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:53,259 : INFO : EPOCH 10 - PROGRESS: at 53.44% examples, 1176722 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:54,260 : INFO : EPOCH 10 - PROGRESS: at 57.81% examples, 1181542 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:55,263 : INFO : EPOCH 10 - PROGRESS: at 61.81% examples, 1180338 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:56,273 : INFO : EPOCH 10 - PROGRESS: at 65.43% examples, 1169274 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:57:57,282 : INFO : EPOCH 10 - PROGRESS: at 68.76% examples, 1159289 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:58,292 : INFO : EPOCH 10 - PROGRESS: at 71.68% examples, 1145170 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:57:59,295 : INFO : EPOCH 10 - PROGRESS: at 75.56% examples, 1145000 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:58:00,302 : INFO : EPOCH 10 - PROGRESS: at 79.52% examples, 1149336 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:58:01,302 : INFO : EPOCH 10 - PROGRESS: at 83.55% examples, 1152663 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:58:02,310 : INFO : EPOCH 10 - PROGRESS: at 87.44% examples, 1152480 words/s, in_qsize 19, out_qsize 0\n",
      "2020-08-29 10:58:03,321 : INFO : EPOCH 10 - PROGRESS: at 91.30% examples, 1149436 words/s, in_qsize 20, out_qsize 0\n",
      "2020-08-29 10:58:04,332 : INFO : EPOCH 10 - PROGRESS: at 94.33% examples, 1138554 words/s, in_qsize 17, out_qsize 2\n",
      "2020-08-29 10:58:05,341 : INFO : EPOCH 10 - PROGRESS: at 97.62% examples, 1131534 words/s, in_qsize 18, out_qsize 1\n",
      "2020-08-29 10:58:05,865 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-08-29 10:58:05,874 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-08-29 10:58:05,879 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-08-29 10:58:05,881 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-08-29 10:58:05,882 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-08-29 10:58:05,883 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-08-29 10:58:05,896 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 10:58:05,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 10:58:05,903 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 10:58:05,906 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 10:58:05,906 : INFO : EPOCH - 10 : training on 41519358 raw words (30346269 effective words) took 26.8s, 1132861 effective words/s\n",
      "2020-08-29 10:58:05,907 : INFO : training on a 415193580 raw words (303494679 effective words) took 227.0s, 1336893 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303494679, 415193580)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at some output \n",
    "This first example shows a simple case of looking up words similar to the word `dirty`. All we need to do here is to call the `most_similar` function and provide the word `dirty` as the positive example. This returns the top 10 similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 11:01:15,433 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8744967579841614),\n",
       " ('unclean', 0.7758036255836487),\n",
       " ('stained', 0.7711732387542725),\n",
       " ('smelly', 0.7667703032493591),\n",
       " ('dusty', 0.7639738321304321),\n",
       " ('grubby', 0.7565650939941406),\n",
       " ('dingy', 0.7385347485542297),\n",
       " ('grimy', 0.7245001792907715),\n",
       " ('soiled', 0.7236559391021729),\n",
       " ('gross', 0.7206484079360962)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.921128511428833),\n",
       " ('friendly', 0.8279157876968384),\n",
       " ('cordial', 0.801971971988678),\n",
       " ('professional', 0.7868619561195374),\n",
       " ('curteous', 0.7700151205062866),\n",
       " ('attentive', 0.7695232629776001)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.694383442401886),\n",
       " ('canada', 0.6543870568275452),\n",
       " ('midwest', 0.630740225315094),\n",
       " ('barcelona', 0.6271055340766907),\n",
       " ('rome', 0.6205963492393494),\n",
       " ('spain', 0.6154872179031372)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8131061792373657),\n",
       " ('amazed', 0.8086591958999634),\n",
       " ('astonished', 0.7797779440879822),\n",
       " ('dismayed', 0.7650278806686401),\n",
       " ('astounded', 0.7474824786186218),\n",
       " ('appalled', 0.7402036786079407)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.7114425301551819),\n",
       " ('mattress', 0.6982126832008362),\n",
       " ('pillowcase', 0.6902005672454834),\n",
       " ('blanket', 0.6881498098373413),\n",
       " ('matress', 0.6708730459213257),\n",
       " ('quilt', 0.6524391770362854),\n",
       " ('sheets', 0.636884331703186),\n",
       " ('pillows', 0.6267510056495667),\n",
       " ('foam', 0.6152631044387817),\n",
       " ('comforter', 0.6020686626434326)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76677036"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26689175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model to a file\n",
    "\n",
    "Use `<model>.save(<file name>)` to save model to a file\n",
    "\n",
    "Use `<model> = KeyedVectors.load(<file name>)` to save model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('review.model.bin')\n",
    "from gensim.models import KeyedVectors\n",
    "model2 = KeyedVectors.load('review.model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 11:18:11,521 : INFO : storing 70537x150 projection weights into review.model.txt\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('review.model.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70537 150\r\n",
      "the -1.0474149 -1.0775484 0.75805414 0.7357467 -0.65385985 -1.2986574 0.8246915 -0.9524938 -2.5136108 -0.004296381 1.9257911 1.5469992 -1.6204963 2.8012848 0.04588041 1.2353007 0.61977947 1.0574156 0.44046468 0.5489067 0.6377579 0.5728992 1.5188081 -1.8405206 0.16099833 0.52852774 0.90188515 1.2018433 1.2751708 -0.35817325 0.5333824 1.3552257 1.0180264 -0.32291555 0.33117554 -0.7084595 0.44710004 0.48289528 0.68740976 0.13262022 1.4459572 0.39889675 0.5991782 1.6264985 0.2768606 -1.2750913 1.2704366 -0.6263162 -3.2955897 -0.2677531 1.4692366 -1.802373 -0.03654402 -0.13222122 -0.5125803 -1.1268432 -0.65204334 -0.9096653 1.3756621 0.6438835 -2.1022336 1.5402129 -2.6617522 -0.8364755 -0.005132524 -2.0893056 0.42927772 -0.70986706 -0.8546314 -1.3894821 -0.9202516 -0.7117637 -1.2846073 -0.58542544 1.5928258 0.48895657 1.2392563 -1.5895292 1.7774339 -0.95572954 -0.69329685 -0.8601518 -2.792009 -0.3416773 0.927962 0.47721827 -0.8427079 -0.047970477 -1.4401464 -1.958336 1.7821808 -0.73950267 3.2522728 2.0775201 -1.1905288 -1.1524051 -0.46830958 -0.6496358 -1.0181516 -0.9352641 -0.059984468 0.779614 0.15649492 1.7279457 -1.7873076 -0.30570713 0.5111812 0.30723578 -0.23658507 -0.74598765 -0.99512726 0.19327861 0.87223834 -1.7582406 -1.4596035 1.3468698 -1.7010982 0.098438926 0.5426549 -1.1301872 -0.2581634 0.2275492 0.033049926 0.862393 0.19830051 0.13499022 0.51461774 -0.33384225 -0.92941636 -0.77681965 0.9473648 -0.3265212 -0.2607505 -1.4221951 0.5364189 0.8541006 -0.025171923 -0.16190477 -1.4241937 0.4560967 -1.3832597 -0.6804551 0.46315053 0.020957757 1.4639761 -1.0853294 0.17593606 0.9420479 -0.06094106 0.5633018\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 review.model.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longmen -0.04464475 0.013499864 0.017939413 0.11016689 -0.035444584 0.019699477 0.11995376 0.0068000094 0.07599533 -0.04476829 0.016287733 -0.036519367 0.048385922 -0.05286206 0.038155362 0.173763 0.06538556 -0.041321516 -0.118958965 -0.16379856 0.04313128 0.102543525 0.030428315 0.03488412 0.023136787 -0.07679798 0.058719795 -0.037489478 0.01734984 0.040495973 -0.029823137 -0.035882834 -0.12941591 0.094231255 -0.13206856 0.005374585 0.062290065 0.019999018 0.077333644 0.048102587 0.013850405 -0.004091791 -0.06944274 0.043887604 0.0037073672 0.075675584 0.18738243 0.04102377 -0.07842261 0.03169691 0.04388537 0.0748127 0.048892267 -0.06649639 0.051919885 -0.043634724 -0.023626395 0.018510515 -0.094644316 -0.015341737 0.024523273 0.093875326 0.036184747 0.100009866 0.104307674 -0.11368899 -0.010508096 0.0053770808 0.23867266 -0.012560841 -0.080248356 0.009368075 -0.13071427 -0.04406637 -0.048579864 -0.067995474 0.023842273 -0.07534184 0.0019154936 -0.03527242 0.012816708 -0.026099375 -0.04388525 0.018795164 0.0767261 0.07779397 0.076338746 -0.042531583 -0.110688776 -0.011973512 -0.01518645 0.02838889 -0.08291124 0.051688105 -0.13169405 -0.055034894 0.07735512 0.045066003 -0.04381737 -0.13246214 -0.031177968 -0.05704546 0.02743056 0.026540484 -0.09903432 -0.061183535 0.013879233 0.03212415 -0.032384325 0.0061629643 0.09988434 0.04271958 -0.020706996 0.13441333 -0.042145118 -0.13016231 -0.014618641 -0.055755064 0.010416254 -0.08459502 -0.13893647 -0.051185414 0.020199703 -0.0479153 0.022306092 -0.063617654 -0.012766445 -0.018443193 -0.067358606 -0.07514606 -0.008521484 -0.037811458 -0.0644317 0.0630772 0.04951492 -0.06644145 -0.0106116785 0.021164257 -0.06685485 -0.031021727 0.033718705 0.06791384 0.025159817 -0.052485697 -0.019405704 -0.04138611 0.048001103 -0.16402124 -0.08909985 0.010528196\r\n",
      "hanzhong -0.103757866 -0.109663315 -0.076273784 0.14305197 -0.044506885 -0.014151334 0.107983716 -0.096323825 0.023828432 -0.061410565 0.012636984 -0.07894611 -0.04621978 -0.08924539 0.02952262 0.059847314 0.012887856 -0.045165338 0.046340633 -0.15602717 0.066330954 0.00290238 -0.1897657 0.14928164 0.02656253 -0.027726002 0.14217016 0.05833463 0.010235135 -0.059656296 -0.015524187 -0.037376914 -0.00823006 0.19662727 -0.12308864 -0.13194272 0.15339185 0.03746916 0.042774513 0.0814268 -0.050679542 0.0790898 -0.005419726 0.024024941 0.021068541 0.08982941 0.02214149 0.035589833 -0.08588475 0.11541707 -0.02243729 0.07660028 -0.012551379 -0.03790174 0.02075807 -0.09501684 0.06189788 -0.028114561 -0.13928743 0.099655755 0.021445394 0.062399507 -0.09381225 0.09240843 0.06899411 -0.029667912 -0.013031364 0.038865663 0.15325068 -0.15585095 -0.14518507 -0.0787653 -0.23774499 0.0102655925 -0.00025916516 0.007935771 0.16586977 0.06731066 -0.10308651 -0.09093961 0.09928976 0.01659706 -0.07412368 0.010516776 0.1289538 -0.018748194 0.0807692 0.06142857 -0.102575734 0.040507145 0.011828918 -0.0038607595 -0.10358409 -0.121576644 -0.065056995 -0.06465039 0.06604133 -0.038816463 -0.040842015 -0.1151269 -0.044138305 -0.18775085 0.069375075 0.07232967 -0.17801003 0.0028986896 -0.033680305 -0.0025167975 -0.06779438 -0.15781787 0.07914207 0.15677826 -0.047059983 0.110940084 -0.11705146 -0.047174 -0.05800731 0.047314893 -0.095094465 -0.27161863 0.009839631 0.02913439 0.099020995 -0.09987289 -0.08171945 0.00460147 -0.021697193 -0.10383593 0.025416508 -0.09302551 -0.009011359 -0.018421762 -0.06771645 0.006895964 -0.0728886 -0.003199494 0.015246131 -0.0058368663 0.027008848 -0.018446745 0.005186993 0.10547422 -0.15732144 -0.07559524 0.029686231 0.047560066 0.08150331 -0.2092786 -0.07285646 -0.0048631774\r\n"
     ]
    }
   ],
   "source": [
    "!tail -2 review.model.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
